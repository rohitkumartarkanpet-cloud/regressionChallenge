
---
title: "Regression & Interpretability: When Linear Models Go Sideways (v6 premium)"
author: "Rohit Kumar, Tarkanpet"
format:
  html:
    theme: darkly
    toc: true
    toc-depth: 2
    smooth-scroll: true
    df-print: paged
execute:
  echo: false
  warning: false
  message: false
---

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.formula.api as smf

# Try to load the data from the starter file
try:
    observDF
except NameError:
    observDF = pd.read_csv("observDF.csv")

# Ensure expected columns and order
observDF = observDF[["Stress", "StressSurvey", "Time", "Anxiety"]]

# Global dark styling for plots
sns.set_theme(style="darkgrid", font_scale=1.15)
plt.rcParams["figure.figsize"] = (8.5, 5)
plt.rcParams["axes.spines.top"] = False
plt.rcParams["axes.spines.right"] = False
plt.rcParams["figure.facecolor"] = "#020617"   # dark slate
plt.rcParams["axes.facecolor"] = "#020617"
plt.rcParams["axes.labelcolor"] = "white"
plt.rcParams["xtick.color"] = "white"
plt.rcParams["ytick.color"] = "white"
plt.rcParams["text.color"] = "white"

# Fit all models once
m_stressSurvey = smf.ols("Anxiety ~ StressSurvey", data=observDF).fit()
m_time_only   = smf.ols("Anxiety ~ Time", data=observDF).fit()
m_survey_time = smf.ols("Anxiety ~ StressSurvey + Time", data=observDF).fit()
m_true_stress = smf.ols("Anxiety ~ Stress + Time", data=observDF).fit()

# Subset for low and moderate stress
subset = observDF[observDF["Stress"] <= 2]
m_subset = smf.ols("Anxiety ~ StressSurvey + Time", data=subset).fit()

def pretty_coef_table(model, title):
    """Return a styled coefficient table with a colorful, compact look."""
    df = pd.DataFrame({
        "Term": model.params.index,
        "Estimate": model.params.values,
        "Std. Error": model.bse.values,
        "t": model.tvalues.values,
        "p-value": model.pvalues.values,
    })
    styler = (
        df.style
          .set_caption(title)
          .set_table_attributes('class="table table-sm table-striped table-hover"')
          .format({
              "Estimate": "{:.3f}",
              "Std. Error": "{:.3f}",
              "t": "{:.2f}",
              "p-value": "{:.6f}",
          })
          .background_gradient(subset=["Estimate"], cmap="PuRd")
          .background_gradient(subset=["t"], cmap="PuRd")
    )
    return styler
```

## Data and true model

The variables in the dataset:

- **Anxiety** – outcome from an fMRI-based anxiety measure  
- **Stress** – "true" stress (blood test)  
- **StressSurvey** – survey-based stress proxy  
- **Time** – time on social media in the last 24 hours  

By construction, the true relationship in the population is:

\[
Anxiety = Stress + 0.1 \times Time
\]

so the true coefficients for a correctly specified model with `Stress` and `Time` are:

- \(\beta_1 = 1\) for Stress  
- \(\beta_2 = 0.1\) for Time  

`StressSurvey` is meant to mimic Stress but with a non-linear distortion.

```{python}
fig, ax = plt.subplots()
sns.lineplot(
    data=observDF.sort_values("Stress"),
    x="Stress", y="StressSurvey",
    marker="o", linewidth=2.5, ax=ax, color="#38bdf8"
)
ax.set_title("How the survey score tracks true stress")
ax.set_xlabel("True Stress (blood test)")
ax.set_ylabel("StressSurvey")
ax.set_ylim(bottom=-0.5)
plt.tight_layout()
plt.show()
```

The survey score increases with true Stress, but the spacing is uneven, especially at higher levels. That warped scale is what will cause trouble later.

---

## Q1 – Bivariate regression: Anxiety on StressSurvey

Model:

\[
Anxiety = \alpha_0 + \alpha_1 \; StressSurvey + \varepsilon.
\]

```{python}
pretty_coef_table(m_stressSurvey, "Bivariate regression: Anxiety ~ StressSurvey")
```

From this fit:

- The slope on **StressSurvey** is positive and statistically significant.  
- \(R^2\) is fairly high, so the model seems to capture most of the variation in Anxiety.  

So each one-unit change in StressSurvey is associated with roughly one extra unit of Anxiety on average.  

Compared to the true model, the target is 1 unit of Anxiety **per unit of Stress**, not per unit of StressSurvey. Because the survey scale is warped, the slope is not directly interpretable as the effect of true stress, even though the fit looks strong.

```{python}
fig, ax = plt.subplots()

# Color points by true Stress to show the hidden structure
sns.scatterplot(
    data=observDF,
    x="StressSurvey", y="Anxiety",
    s=90, edgecolor="white", linewidth=0.7,
    hue="Stress", palette="viridis", ax=ax
)

# Add fitted line
x_vals = np.linspace(observDF["StressSurvey"].min(), observDF["StressSurvey"].max(), 200)
y_hat  = m_stressSurvey.params["Intercept"] + m_stressSurvey.params["StressSurvey"] * x_vals
ax.plot(x_vals, y_hat, color="#f97316", linewidth=3, label="Fitted line")

ax.set_title("Anxiety vs. StressSurvey (bivariate fit)")
ax.set_xlabel("StressSurvey")
ax.set_ylabel("Anxiety")
ax.legend(title="True Stress", bbox_to_anchor=(1.03, 1), loc="upper left", frameon=True)
plt.tight_layout()
plt.show()
```

The scatter has a gentle curve, and the straight regression line cuts through the middle. That already hints that a single constant slope is an oversimplification of how Anxiety responds to Stress in this dataset.

---

## Q2 – Bivariate regression: Anxiety on Time

Now regress Anxiety on Time only:

\[
Anxiety = \gamma_0 + \gamma_1 \; Time + \varepsilon.
\]

```{python}
pretty_coef_table(m_time_only, "Bivariate regression: Anxiety ~ Time")
```

From this fit:

- The slope on **Time** is positive and statistically significant.  
- The estimated effect of Time is much larger than the true marginal effect of 0.1 that we know is built into the data.  

The model is assigning too much credit to Time. In this design, Time and Stress are related, so Time acts as a **proxy** for Stress when Stress is not in the equation.

```{python}
fig, ax = plt.subplots()

sns.scatterplot(
    data=observDF,
    x="Time", y="Anxiety",
    s=95, edgecolor="white", linewidth=0.7,
    hue="StressSurvey", palette="magma", ax=ax
)

x_vals = np.linspace(observDF["Time"].min(), observDF["Time"].max(), 200)
y_hat  = m_time_only.params["Intercept"] + m_time_only.params["Time"] * x_vals
ax.plot(x_vals, y_hat, color="#22c55e", linewidth=3, label="Fitted line")

ax.set_title("Anxiety vs. time on social media (bivariate fit)")
ax.set_xlabel("Time on social media")
ax.set_ylabel("Anxiety")
ax.legend(title="StressSurvey", bbox_to_anchor=(1.03, 1), loc="upper left", frameon=True)
plt.tight_layout()
plt.show()
```

Visually this looks like a clean positive relationship: students who spend more time on social media also tend to have higher Anxiety. But the slope is mostly picking up the pattern that higher-stress students also tend to appear at higher Time values.

---

## Q3 – Multiple regression with StressSurvey and Time

Next, add both predictors:

\[
Anxiety = \delta_0 + \delta_1 \; StressSurvey + \delta_2 \; Time + \varepsilon.
\]

```{python}
pretty_coef_table(m_survey_time, "Multiple regression: Anxiety ~ StressSurvey + Time")
```

The key results are:

- The coefficient on **StressSurvey** is positive and statistically significant.  
- The coefficient on **Time** is **negative**, and in this dataset it is not statistically significant at the 5% level.  
- \(R^2\) is high, so the model looks excellent on standard metrics.

The striking part is the **sign flip**: in the true data-generating process, more Time *increases* Anxiety slightly, but once we "control" for StressSurvey, the model suggests that more Time is associated with *lower* Anxiety.

```{python}
true_vals = pd.DataFrame({
    "Model": ["True coefficients"],
    "Stress_like": [1.0],
    "Time": [0.1]
})

survey_model_vals = pd.DataFrame({
    "Model": ["Uses StressSurvey + Time"],
    "Stress_like": [m_survey_time.params["StressSurvey"]],
    "Time": [m_survey_time.params["Time"]],
})

coef_df = (
    pd.concat([true_vals, survey_model_vals], ignore_index=True)
      .melt(id_vars="Model", var_name="Coefficient", value_name="Estimate")
)

fig, ax = plt.subplots()
sns.barplot(
    data=coef_df,
    x="Coefficient", y="Estimate",
    hue="Model", ax=ax, edgecolor="white", palette="coolwarm"
)
ax.axhline(0, color="white", linewidth=1)
ax.set_title("True coefficients vs. model using StressSurvey + Time")
ax.set_ylabel("Estimated value")
plt.tight_layout()
plt.show()
```

Even with a high \(R^2\) and small p-values for at least one predictor, the model suggests the opposite of the truth about social media time. The non-linear survey proxy is bending the regression in a misleading direction.

---

## Q4 – Multiple regression with true Stress and Time

Now fit the model that uses the underlying Stress measure instead of the proxy:

\[
Anxiety = \beta_0 + \beta_1 \; Stress + \beta_2 \; Time + \varepsilon.
\]

```{python}
pretty_coef_table(m_true_stress, "Multiple regression: Anxiety ~ Stress + Time")
```

From this specification:

- The coefficient on **Stress** is positive and reasonably close to the true value of 1.  
- The coefficient on **Time** is much smaller in magnitude than in the earlier models, but in this dataset it may still be imprecise and can even have the wrong sign.  
- The overall \(R^2\) remains high.

This shows that even when we use a more direct measure of stress, small sample size and the particular design of the data can leave the estimated Time effect unstable. The model with true Stress is clearly closer to the data-generating story, but it still reminds us not to over-interpret individual coefficients just because they appear in a nice summary table.

```{python}
true_vals2 = pd.DataFrame({
    "Model": ["True coefficients"],
    "Stress_like": [1.0],
    "Time": [0.1]
})

stress_model_vals = pd.DataFrame({
    "Model": ["Uses Stress + Time"],
    "Stress_like": [m_true_stress.params["Stress"]],
    "Time": [m_true_stress.params["Time"]],
})

coef_df2 = (
    pd.concat([true_vals2, stress_model_vals], ignore_index=True)
      .melt(id_vars="Model", var_name="Coefficient", value_name="Estimate")
)

fig, ax = plt.subplots()
sns.barplot(
    data=coef_df2,
    x="Coefficient", y="Estimate",
    hue="Model", ax=ax, edgecolor="white", palette="mako"
)
ax.axhline(0, color="white", linewidth=1)
ax.set_title("True coefficients vs. model using Stress + Time")
ax.set_ylabel("Estimated value")
plt.tight_layout()
plt.show()
```

The model that uses StressSurvey gives a large and misleading Time effect. The model with true Stress brings the Stress coefficient close to 1 and the Time coefficient much closer to the small true effect, but it still illustrates how fragile coefficient interpretation can be in small samples.

---

## Q5 – How headlines could mislead people

If the StressSurvey + Time model were reported in the news, a headline might read:

> "After accounting for stress, more time on social media is linked to lower anxiety."

Everything in the regression table would look legitimate: high \(R^2\), statistically significant predictors, and tidy standard errors. Parents reading that headline might feel reassured; social-media companies would be happy to promote it.

If the model with true Stress were reported, a more realistic headline could be:

> "More time on social media is associated with higher anxiety, even after controlling for stress."

The two models are estimated on the same data but tell opposite stories. The difference comes entirely from how stress is measured and modeled.

---

## Q6 – Subset analysis: focusing on a more linear region

The main distortion comes from how the survey compresses the high-stress range. To see what happens when the relationship is closer to linear, restrict the sample to

\[
Stress \le 2,
\]

where `StressSurvey` is approximately three times Stress.

```{python}
pretty_coef_table(m_subset, "Subset regression: Anxiety ~ StressSurvey + Time (Stress ≤ 2)")
```

On this subset:

- The coefficient on **StressSurvey** is positive and roughly one-third of what we would expect for true Stress, which lines up with the fact that `StressSurvey ≈ 3 × Stress` in this region.  
- The coefficient on **Time** is small in magnitude and not statistically distinguishable from zero.  

```{python}
fig, ax = plt.subplots()

# All data in muted gray
sns.scatterplot(
    data=observDF,
    x="StressSurvey", y="Anxiety",
    color="#4b5563", s=70, ax=ax, label="All data"
)

# Highlight subset
sns.scatterplot(
    data=subset,
    x="StressSurvey", y="Anxiety",
    s=110, edgecolor="white", linewidth=0.9,
    color="#e11d48", ax=ax, label="Subset: Stress ≤ 2"
)

# Fitted line on subset (holding Time at its mean in the subset)
x_vals = np.linspace(subset["StressSurvey"].min(), subset["StressSurvey"].max(), 200)
y_hat_subset = (
    m_subset.params["Intercept"]
    + m_subset.params["StressSurvey"] * x_vals
    + m_subset.params["Time"] * subset["Time"].mean()
)
ax.plot(
    x_vals, y_hat_subset,
    color="#a855f7", linewidth=3,
    label="Subset fit (holding Time at mean)"
)

ax.set_title("Focusing on the region where the survey behaves more linearly")
ax.set_xlabel("StressSurvey")
ax.set_ylabel("Anxiety")
ax.legend(bbox_to_anchor=(1.03, 1), loc="upper left", frameon=True)
plt.tight_layout()
plt.show()
```

When the proxy behaves almost linearly, the regression has a much easier time recovering a sensible relationship between StressSurvey and Anxiety. Once the strongly non-linear part of the scale is folded in, the slopes swing to unrealistic values, including sign flips.

---

## Takeaways

- A high \(R^2\) and statistically significant coefficients do **not** guarantee that the slopes tell a sensible story.  
- Using a non-linear proxy (like StressSurvey) in place of a more direct measure (Stress) can completely change, or even invert, the apparent effect of another variable (Time).  
- Visual checks, thinking carefully about how variables are measured, and exploring subsets where relationships are closer to linear are essential before trusting a linear regression model for interpretation.
